{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glove - Busca por Similaridade.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMx5C6m9rNrmzHo/KdaVM+C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaoSouza2121/pln/blob/main/Glove_Busca_por_Similaridade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwpcW6Uua1w1"
      },
      "source": [
        "##Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbz4XfHVa6Vg"
      },
      "source": [
        "##<font color=\"orange\">Processamento de Linguagem Natural</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uxQqhLfbG3I"
      },
      "source": [
        "# Buscador de Palavras em Texto por Similaridade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsr5tiuRb6JE"
      },
      "source": [
        "# Explicação:\n",
        "Modelo GloVe\n",
        "O GloVe é uma técnica de vetor de palavras (embeddings). Os vetores de palavras\n",
        "colocam as palavras em um espaço vetorial, onde palavras semelhantes se agrupam e palavras\n",
        "diferentes se repelem. A vantagem do GloVe é que, diferentemente do Word2vec, o GloVe não\n",
        "depende apenas de estatísticas locais (informações de contexto local das palavras), mas\n",
        "incorpora estatísticas globais (co-ocorrência de palavras) para obter vetores de palavras. Mas\n",
        "há bastante sinergia entre o GloVe e o Word2vec.\n",
        "E não se surpreenda ao saber que a ideia de usar estatísticas globais para derivar\n",
        "relacionamentos semânticos entre palavras remonta a um longo caminho. GloVe significa\n",
        "\"Global Vectors” ou “Vetores Globais\". E, como mencionado anteriormente, o GloVe captura\n",
        "estatísticas globais e estatísticas locais de um corpus, a fim de criar vetores de palavras. Mas\n",
        "precisamos de estatísticas globais e locais?\n",
        "Acontece que cada tipo de estatística tem sua própria vantagem. Por exemplo, o\n",
        "Word2vec, que captura estatísticas locais, se sai muito bem em tarefas de analogia. No entanto,\n",
        "um método como o LSA (Latent Semantic Analysis), que usa apenas estatísticas globais, não\n",
        "funciona bem em tarefas de analogia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDmL-DOTalh9",
        "outputId": "f3f95850-8f18-44f8-ed3f-0097e7be6caa"
      },
      "source": [
        "# Imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch.autograd import Variable\n",
        "from nltk.tokenize import word_tokenize\n",
        "%matplotlib inline\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4491ee8910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmP-wMJXcgJA",
        "outputId": "0fa3ad9b-41c7-414f-f0ba-62f536acabcf"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G9NVHeVdBU3"
      },
      "source": [
        "##Carregando e Processando os Dados\n",
        "Para este estudo de caso, usaremos o famoso texto de Isaac Asimov: The Last Question.\n",
        "\n",
        "http://users.ece.cmu.edu/~gamvrosi/thelastq.html\n",
        "\n",
        "Traduzimos o texto e usaremos para treinar o modelo GloVe e depois buscar palavras por similaridade. Recomendados a leitura do arquivo asimov.txt (usado na célula abaixo) antes de executar o restante do Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-PlnFFPcsCB"
      },
      "source": [
        "# Abre o arquivo para leitura e carrega na variável arquivo_texto\n",
        "arquivo_texto = open('dados/asimov.txt', 'r')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCEN_i0DdpB5"
      },
      "source": [
        "# Converte as palavars para minúsculo\n",
        "texto = arquivo_texto.read().lower()\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvvD5PE2dtNR"
      },
      "source": [
        "# Fecha o arquivo\n",
        "arquivo_texto.close()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzONpkS2dvaJ"
      },
      "source": [
        "# Tokenização do texto\n",
        "texto_token = word_tokenize(texto)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSRoSNUrd-Za"
      },
      "source": [
        "# Variável para o comprimento total dos tokens\n",
        "comp_tokens = len(texto_token)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZAc3bn1eCDh",
        "outputId": "7c066c22-5afa-4f79-f984-d5f9972a1e6f"
      },
      "source": [
        "print(\"Número de Tokens: \", comp_tokens)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número de Tokens:  5280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clJMo8v8eKu0"
      },
      "source": [
        "# Criando o Vocabulário"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zffr7kTqeIpO",
        "outputId": "f706edec-9ab1-43a2-d69b-916959d0b6da"
      },
      "source": [
        "# Criando o vocabulário\n",
        "vocab = set(texto_token)\n",
        "vocab_size = len(vocab)\n",
        "print(\"Tamanho do Vocabulário:\", vocab_size)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamanho do Vocabulário: 1397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dNlzsn0epgR"
      },
      "source": [
        "# Dicionário para mapear as palavras aos índices\n",
        "palavra_indice = {palavra: i for i, palavra in enumerate(vocab)}\n",
        "palavra_indice\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS_mnb-RetqB"
      },
      "source": [
        "# Dicionário para mapear os índices às palavras\n",
        "indice_palavra = {i: palavra for i, palavra in enumerate(vocab)}\n",
        "indice_palavra"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBCjKUkTe6Tg"
      },
      "source": [
        "Salvo indicação contrário, usamos um contexto de dez palavras à esquerda e dez palavras à direita."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS_1Bojzeyf_"
      },
      "source": [
        "# Tamanho do contexto\n",
        "CONTEXT_SIZE = 10"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vfNFaP6fTUR",
        "outputId": "6e50320b-7a5a-4c0d-de6f-82f1329f9065"
      },
      "source": [
        "# Matriz de co-ocorrência preenchida com zeros\n",
        "co_occ_mat = np.zeros((vocab_size, vocab_size))\n",
        "co_occ_mat\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blaUioDXfihN"
      },
      "source": [
        "Agora percorremos os dicionários de mapeamentos criados anteriormente e preenchemos a matriz de co-ocorrencia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-fxEeofffd9"
      },
      "source": [
        "# Loop externo por todo comprimento do vocabulário\n",
        "for i in range(comp_tokens):\n",
        "   \n",
        "    # Loop interno pelo tamanho do contexto\n",
        "    for dist in range(1, CONTEXT_SIZE + 1):\n",
        "       \n",
        "        # Obtém o índice do token\n",
        "        ix = palavra_indice[texto_token[i]]\n",
        "       \n",
        "        # Se a palara estiver à esquerda, inserimos à esquerda na matriz de co-ocorrência\n",
        "        if i - dist > 0:\n",
        "            left_ix = palavra_indice[texto_token[i - dist]]\n",
        "            co_occ_mat[ix, left_ix] += 1.0 / dist\n",
        "           \n",
        "        # Se a palara estiver à direita, inserimos à direita na matriz de co-ocorrência\n",
        "        if i + dist < len(texto_token):\n",
        "            right_ix = palavra_indice[texto_token[i + dist]]\n",
        "            co_occ_mat[ix, right_ix] += 1.0 / dist\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YlLwzvsgAag"
      },
      "source": [
        "# Transposta da matriz de co-ocorrências\n",
        "# Retorna um array 2-D com uma linha para cada elemento não-zero\n",
        "co_occs = np.transpose(np.nonzero(co_occ_mat))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVTV6LvvgUyu",
        "outputId": "78330dd2-3b7f-4410-8d25-bcb97fc4de00"
      },
      "source": [
        "# Print\n",
        "print(\"Shape da Matriz de Co-Ocorrência:\", co_occ_mat.shape)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape da Matriz de Co-Ocorrência: (1397, 1397)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVB9HGtUgYt-",
        "outputId": "ec3e437d-0ae0-41a0-a3cc-26bb9111fe61"
      },
      "source": [
        "# Print\n",
        "print(\"Matriz de Co-Ocorrência Não-Zero:\\n\", co_occs)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz de Co-Ocorrência Não-Zero:\n",
            " [[   0    9]\n",
            " [   0   45]\n",
            " [   0  217]\n",
            " ...\n",
            " [1396 1352]\n",
            " [1396 1361]\n",
            " [1396 1396]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgI6syDeghgF"
      },
      "source": [
        "# Criando o Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtr-UdsKgdek"
      },
      "source": [
        "# Tamanho da embedding\n",
        "EMBEDDING_SIZE = 50"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92SStBeegzue"
      },
      "source": [
        "# Hiperparâmetros\n",
        "X_MAX = 100\n",
        "ALPHA = 0.75\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.05\n",
        "EPOCHS = 200\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z40XJFveg3XP"
      },
      "source": [
        "# Classe para o modelo\n",
        "class Glove(nn.Module):\n",
        "\n",
        "    # Método construtor\n",
        "    def __init__(self, vocab_size, comat, embedding_size, x_max, alpha):\n",
        "        super(Glove, self).__init__()\n",
        "       \n",
        "        # Matriz de embeddings com as palavras centrais\n",
        "        self.embedding_V = nn.Embedding(vocab_size, embedding_size)\n",
        "       \n",
        "        # Matriz de embeddings com as palavras de contexto\n",
        "        self.embedding_U = nn.Embedding(vocab_size, embedding_size)\n",
        "\n",
        "        # Bias\n",
        "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
        "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
        "       \n",
        "        # Inicializa os parâmtetros (pesos que a rede aprende durante o treinamento)\n",
        "        for params in self.parameters():\n",
        "            nn.init.uniform_(params, a = -0.5, b = 0.5)\n",
        "           \n",
        "        # Define os hiperparâmetros (que controlam o treinamento)\n",
        "        self.x_max = x_max\n",
        "        self.alpha = alpha\n",
        "        self.comat = comat\n",
        "   \n",
        "    # Função de forward\n",
        "    def forward(self, center_word_lookup, context_word_lookup):\n",
        "       \n",
        "        # Matrizes embedding de pesos para centro e contexto\n",
        "        center_embed = self.embedding_V(center_word_lookup)\n",
        "        target_embed = self.embedding_U(context_word_lookup)\n",
        "\n",
        "        # Matrizes embedding de bias para centro e contexto\n",
        "        center_bias = self.v_bias(center_word_lookup).squeeze(1)\n",
        "        target_bias = self.u_bias(context_word_lookup).squeeze(1)\n",
        "\n",
        "        # Elementos da matriz de co-ocorrência\n",
        "        co_occurrences = torch.tensor([self.comat[center_word_lookup[i].item(), context_word_lookup[i].item()]\n",
        "                                       for i in range(BATCH_SIZE)])\n",
        "       \n",
        "        # Carrega os pesos\n",
        "        weights = torch.tensor([self.weight_fn(var) for var in co_occurrences])\n",
        "\n",
        "        # Funçã de perda\n",
        "        loss = torch.sum(torch.pow((torch.sum(center_embed * target_embed, dim = 1)\n",
        "            + center_bias + target_bias) - torch.log(co_occurrences), 2) * weights)\n",
        "       \n",
        "        return loss\n",
        "       \n",
        "    # Definição do peso\n",
        "    def weight_fn(self, x):\n",
        "        if x < self.x_max:\n",
        "            return (x / self.x_max) ** self.alpha\n",
        "        return 1\n",
        "       \n",
        "    # Soma de V e U como nossos vetores de palavras\n",
        "    def embeddings(self):\n",
        "        return self.embedding_V.weight.data + self.embedding_U.weight.data\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0JQvRldg9Ed"
      },
      "source": [
        "# Função para gerar um bacth de palavras\n",
        "def gera_batch(model, batch_size = BATCH_SIZE):\n",
        "   \n",
        "    # Extrai uma amostra\n",
        "    sample = np.random.choice(np.arange(len(co_occs)), size = batch_size, replace = False)\n",
        "   \n",
        "    # Listas de vetores\n",
        "    v_vecs_ix, u_vecs_ix = [], []\n",
        "   \n",
        "    # Loop pela amostra para gerar os vetores\n",
        "    for chosen in sample:\n",
        "        ind = tuple(co_occs[chosen])  \n",
        "       \n",
        "        lookup_ix_v = ind[0]\n",
        "        lookup_ix_u = ind[1]\n",
        "       \n",
        "        v_vecs_ix.append(lookup_ix_v)\n",
        "        u_vecs_ix.append(lookup_ix_u)\n",
        "       \n",
        "    return torch.tensor(v_vecs_ix), torch.tensor(u_vecs_ix)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qat36X8chjE-"
      },
      "source": [
        "# Treinamento do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EilYmwsuhgg1"
      },
      "source": [
        "# Função para o treinamento\n",
        "def treina_glove(comat):\n",
        "   \n",
        "    # Lista para os erros\n",
        "    losses = []\n",
        "   \n",
        "    # Cria o modelo Glove\n",
        "    model = Glove(vocab_size, comat, embedding_size = EMBEDDING_SIZE, x_max = X_MAX, alpha = ALPHA)\n",
        "   \n",
        "    # Otimizador\n",
        "    optimizer = optim.Adagrad(model.parameters(), lr = LEARNING_RATE)\n",
        "   \n",
        "    # Loop pelo número de épocas\n",
        "    for epoch in range(EPOCHS):\n",
        "       \n",
        "        # Erro total\n",
        "        total_loss = 0\n",
        "       \n",
        "        # Número de bacthes\n",
        "        num_batches = int(len(texto_token) / BATCH_SIZE)\n",
        "       \n",
        "        # Loop pelos batches\n",
        "        for batch in tqdm(range(num_batches)):\n",
        "           \n",
        "            # Zera os gradientes do modelo\n",
        "            model.zero_grad()\n",
        "           \n",
        "            # Obtém o bacth de dados\n",
        "            data = gera_batch(model, BATCH_SIZE)\n",
        "           \n",
        "            # Calcula o erro\n",
        "            loss = model(*data)\n",
        "           \n",
        "            # Executa o backpropagation\n",
        "            loss.backward()\n",
        "           \n",
        "            # Otimiza os pesos (aqui é onde ocorre o aprendizado)\n",
        "            optimizer.step()\n",
        "           \n",
        "            # Erro total para a epoch\n",
        "            total_loss += loss.item()\n",
        "           \n",
        "        # Erros do modelo\n",
        "        losses.append(total_loss)\n",
        "       \n",
        "        # Print da epoch e erro médio do modelo\n",
        "        print('Epoch : %d, Erro Médio : %.02f' % (epoch, np.mean(losses)))\n",
        "       \n",
        "    return model, losses \n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Oe74UGJhn31"
      },
      "source": [
        "# Executa a função de treinamento e retorna o modelo e os erros\n",
        "model, losses = treina_glove(co_occ_mat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heo-NcD5iAmw"
      },
      "source": [
        "# Função para o plot do erro durante o treinamento\n",
        "def plot_loss(losses, title):\n",
        "    plt.plot(range(len(losses)), losses)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Erro')\n",
        "    plt.title(title)\n",
        "    plt.figure()\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "b_DTkvEXiy0H",
        "outputId": "b72202c5-39e2-4368-b742-9ef36a1ce15b"
      },
      "source": [
        " #Plot\n",
        "plot_loss(losses, \"Erro de Treinamento do Modelo GloVe\")\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFiM-9ovi7tW"
      },
      "source": [
        "# Testando o Modelo: Similaridade de Palavras, analogias de palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRYNgKizi0UL"
      },
      "source": [
        "# Função que retorna a embedding de uma palavra\n",
        "def get_palavra(palavra, modelo, word_to_ix):\n",
        "    return model.embeddings()[word_to_ix[palavra]]\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k6VidhjjYGb"
      },
      "source": [
        "# Função para busca a palavra mais próxima\n",
        "def busca_palavra_similaridade(vec, word_to_ix, n = 10):\n",
        "    all_dists = [(w, torch.dist(vec, get_palavra(w, model, palavra_indice))) for w in palavra_indice]\n",
        "    return sorted(all_dists, key = lambda t: t[1])[:n]\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz1zAouYjjej",
        "outputId": "44bb9e3b-a34b-4973-9dc2-8ebbee05a6e9"
      },
      "source": [
        "# Gerando o vetor (embedding) de uma palavra\n",
        "vector = get_palavra(\"espaço\", model, palavra_indice)\n",
        "print(vector)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.0338,  0.0572, -0.2651, -0.0679, -0.0976, -0.0937, -0.3609,  0.1183,\n",
            "         0.4219,  0.1641,  0.6276,  0.5438,  0.1203, -0.5673, -0.6537,  0.5765,\n",
            "        -0.3577,  0.0538, -0.2022, -1.0117,  0.2263,  0.5679, -0.4865,  0.6525,\n",
            "         0.0322, -0.4019,  0.6047, -0.6956, -0.3045, -0.4991, -0.2562,  0.0011,\n",
            "         0.0481,  0.1110,  0.8083, -0.1469, -0.2711, -0.3911, -0.8739,  0.9562,\n",
            "        -0.2607, -0.1935,  0.1569, -0.5518,  0.0555,  0.0216, -0.2354,  0.1889,\n",
            "         0.6528, -0.2485])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fymX30XBjnWX",
        "outputId": "75cb16dd-3b0f-4656-85a2-e20783788e52"
      },
      "source": [
        "# Busca as palavras similares à palavra \"espaço\"\n",
        "busca_palavra_similaridade(vector, palavra_indice)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('espaço', tensor(0.)),\n",
              " ('pouco', tensor(3.2115)),\n",
              " ('no', tensor(3.2283)),\n",
              " ('sim', tensor(3.3201)),\n",
              " ('antigo', tensor(3.4414)),\n",
              " ('planeta', tensor(3.4560)),\n",
              " ('descansando', tensor(3.4854)),\n",
              " ('seu', tensor(3.4933)),\n",
              " ('diâmetro', tensor(3.5244)),\n",
              " ('sucessor', tensor(3.5382))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK4nwKYRkOQT"
      },
      "source": [
        "Observe que a palavra \"espaço\" tem 0 de distância para si mesma. A próxima palavra mais parecida com \"espaço\" é \"universo\" e assim por diante. Quanto menor a distância, mais parecida a palavra. Lembrando que a busca por similaridade é feita com as embeddings treinadas com o modelo GloVe.\n",
        "\n",
        "Mais um exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMPH5T53kFm8",
        "outputId": "4b229a68-591c-4c40-c4ed-9ade8e89308f"
      },
      "source": [
        "# Gerando o vetor (embedding) de uma palavra\n",
        "vector = get_palavra(\"solar\", model, palavra_indice)\n",
        "print(vector)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.8191,  0.4353,  0.2192,  0.6608,  0.6377, -0.4522, -0.4777,  0.0593,\n",
            "        -0.4341, -0.7913,  0.3298,  0.0751, -0.4017,  0.3436, -0.5646,  0.1447,\n",
            "        -0.3674,  0.5787,  0.5693, -0.0170, -0.1102,  0.3164, -0.2024,  0.1927,\n",
            "         0.2130, -1.2175, -0.4340, -0.3242, -0.3150, -0.5407, -0.6829, -0.1803,\n",
            "         0.1688, -0.3890,  0.5417,  0.2501, -0.4036,  0.4572, -0.1157, -0.5564,\n",
            "        -0.0463,  0.0216, -0.1276, -0.1593,  0.3248,  1.0802, -0.1734, -0.2868,\n",
            "        -0.3379, -0.8608])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3-d8yZpkWcX",
        "outputId": "8532075a-c13b-4dac-b106-5ee21f973b6c"
      },
      "source": [
        "# Busca as palavras similares à palavra \"solar\"\n",
        "busca_palavra_similaridade(vector, palavra_indice)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('solar', tensor(0.)),\n",
              " ('energia', tensor(3.0961)),\n",
              " ('prime', tensor(3.2037)),\n",
              " ('ajudar.', tensor(3.5373)),\n",
              " ('por', tensor(3.5435)),\n",
              " ('zee', tensor(3.5688)),\n",
              " ('unidades', tensor(3.5804)),\n",
              " ('imortalidade', tensor(3.5945)),\n",
              " ('proporção', tensor(3.6086)),\n",
              " ('seus', tensor(3.6537))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BxDcVr5lHGU"
      },
      "source": [
        "A distância da palavra \"solar\" para si mesma é 0 e a palavra com maior similaridade é \"energia\" o que faz todo sentido se você leu o texto do Asimov usado para treinar o modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNnVRMMskche"
      },
      "source": [
        "# Função para busca de palavra por analogia\n",
        "def busca_analogia(p1, p2, p3, n = 5, filtro = True):\n",
        "   \n",
        "    # Print\n",
        "    print('\\n[%s : %s :: %s : ?]' % (p1, p2, p3))\n",
        "   \n",
        "    # p2 - p1 + p3 = p4\n",
        "    closest_words = busca_palavra_similaridade(get_palavra(p2, model, palavra_indice) -\n",
        "                                               get_palavra(p1, model, palavra_indice) +\n",
        "                                               get_palavra(p3, model, palavra_indice),\n",
        "                                               palavra_indice)\n",
        "   \n",
        "    # Vamos excluir as 3 palavras passadas como parâmetro\n",
        "    if filtro:\n",
        "        closest_words = [t for t in closest_words if t[0] not in [p1, p2, p3]]\n",
        "       \n",
        "    for tuple in closest_words[:n]:\n",
        "        print('(%.4f) %s' % (tuple[1], tuple[0]))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrRZ3hDllN98",
        "outputId": "579f4907-25bb-400c-a64b-10482b96bdfa"
      },
      "source": [
        "# Busca por analogia\n",
        "busca_analogia(\"família\", \"crianças\", \"humano\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[família : crianças :: humano : ?]\n",
            "(4.6018) encontravam\n",
            "(4.6358) teria\n",
            "(4.6845) perguntar\n",
            "(4.7729) momentânea\n",
            "(4.7739) microvac\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRU39j3klfL5"
      },
      "source": [
        "E aí estão as palavras que melhor se encaixam na quarta palavra, de acordo com nosso modelo.\n",
        "\n",
        "Quanto maior a distância, menor a similaridade! Treine o modelo com seus próprios textos e experimente a busca por similaridade."
      ]
    }
  ]
}